{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contens:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contens', does not exist in the graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[1;32m-> 1080\u001b[1;33m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[0;32m   1081\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3478\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3519\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3520\u001b[1;33m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[0;32m   3521\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'DecodeJpeg/contens:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contens', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e341ae6d9f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m#载入图片\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mimage_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'DecodeJpeg/contens:0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;31m#图片格式是jpg格式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1081\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m             raise TypeError(\n\u001b[1;32m-> 1083\u001b[1;33m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contens:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contens', does not exist in the graph."
     ]
    }
   ],
   "source": [
    "class NodeLookup(object):\n",
    "    def _init_(self):\n",
    "        label_lookup_path='inception_model/imagenet_2012_challenge_label_map_proto,pbtxt'\n",
    "        uid_lookup_path='inception_model/imagenet_synset_to_human_label_map.txt'\n",
    "        self.node_lookup=self.load(label_lookup_path,uid_lookup_path)\n",
    "        \n",
    "    def load(self,label_lookup_path,uid_lookup_path):\n",
    "        #加载分类字符串对应分类名称的文件\n",
    "        proto_as_ascii_lines=tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human={}\n",
    "        #一行一行读取数据\n",
    "        for line in proto_as_ascii_lines:\n",
    "            #去掉换行符\n",
    "            line=line.strip(\"\\n\")\n",
    "            #按照\\t分割\n",
    "            parsed_items=line.split(\"\\t\")\n",
    "            #获取分类编号\n",
    "            uid=parsed_items[0]\n",
    "            #获取分类名称\n",
    "            human_string=parsed_items[1]\n",
    "            #保持编号与分类名称映射关系\n",
    "            uid_to_human[uid]=human_string\n",
    "        \n",
    "        #加载分类字符串对应分类编号1-1000的文件\n",
    "        proto_as_ascii=tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        node_id_to_uid={}\n",
    "        for line in proto_as_ascii:\n",
    "            if line_startswith(\"target_class\"):\n",
    "                #获取分类编号1-1000\n",
    "                target_class=int(line_split(\":\")[1])\n",
    "            if line.startswith(\"target_class_string\"):\n",
    "                #获取编号字符串\n",
    "                target_class_string=line.split(\":\")[1]\n",
    "                #保存编号与字符串的映射\n",
    "                node_id_to_uid[target_class]=target_class_string[1:-2]\n",
    "        \n",
    "        #建立分类编号1-1000与对应分类名称的映射关系\n",
    "        node_id_to_name={}\n",
    "        for key,val in node_id_to_uid.items():\n",
    "            #获取分类名称\n",
    "            name=uid_to_human[val]\n",
    "            #建立分类编号与分类名称的映射关系\n",
    "            node_id_to_name[key]=name\n",
    "        return node_id_to_name\n",
    "    \n",
    "    #传入分类编号1-1000返回分类名称\n",
    "    def id_to_string(self,node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return\"\"\n",
    "        return self.node_lookup[node_id]\n",
    "\n",
    "#创建一个图来存放Google训练好的模型\n",
    "with tf.gfile.FastGFile(\"inception_model/classify_image_graph_def.pb\",'rb') as f:\n",
    "    graph_def=tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def,name='')\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor=sess.graph.get_tensor_by_name(\"softmax:0\")\n",
    "    #遍历目录\n",
    "    for root,dirs,files in os.walk(\"images/\"):\n",
    "        for file in files:\n",
    "            #载入图片\n",
    "            image_data=tf.gfile.FastGFile(os.path.join(root,file),'rb').read()\n",
    "            predictions=sess.run(softmax_tensor,{'DecodeJpeg/contens:0':image_data})\n",
    "            #图片格式是jpg格式\n",
    "            predictions=np.squeeze(predictions)\n",
    "            #把结果转为1维数据\n",
    "            \n",
    "            #打印图片路径及名称\n",
    "            image_path=os.path.join(root,file)\n",
    "            print(image_data)\n",
    "            #显示图片\n",
    "            img=Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            \n",
    "            #排序\n",
    "            top_k=predictions.argsort()[-5:][::-1]\n",
    "            #先取后五个，再倒序\n",
    "            node_lookup=NodeLookup()\n",
    "            for node_id in top_k:\n",
    "                #获取分类名称\n",
    "                human_string=node_lookup.id_to_string(node_id)\n",
    "                #获取该分类的置信度\n",
    "                score=predictions[node_id]\n",
    "                print(\"%s(score[%.5f])\"%(human_string,score))\n",
    "            print()\n",
    "        \n",
    "                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
